"""
ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸
RAGAS í‰ê°€ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ë° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
"""

import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sqlite3
from pathlib import Path
import json

def show_performance_monitor():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë©”ì¸ í™”ë©´"""
    st.header("âš¡ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
    
    st.markdown("""
    ğŸ¯ **RAGAS í‰ê°€ ì‹œìŠ¤í…œì˜ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ëª¨ë‹ˆí„°ë§**
    
    ì‹¤ì œ í‰ê°€ ì‹¤í–‰ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ëŠ¥ì„ ì¶”ì í•©ë‹ˆë‹¤.
    """)
    
    # ì‹¤ì œ ë°ì´í„° í™•ì¸
    evaluation_history = load_evaluation_history_for_performance()
    
    if not evaluation_history:
        st.warning("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ í‰ê°€ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë¨¼ì € ëª‡ ë²ˆì˜ í‰ê°€ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.info("ğŸ’¡ ìµœì†Œ 3íšŒ ì´ìƒì˜ í‰ê°€ ì‹¤í–‰ í›„ ì˜ë¯¸ìˆëŠ” ì„±ëŠ¥ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„ (ì‹¤ì œ ë°ì´í„°ë§Œ)
    tab1, tab2 = st.tabs(["â±ï¸ í‰ê°€ ì´ë ¥", "ğŸ“Š API ì‚¬ìš©í˜„í™©"])
    
    with tab1:
        show_evaluation_history_analysis(evaluation_history)
    
    with tab2:
        show_api_usage_analysis(evaluation_history)

def load_evaluation_history_for_performance():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ í‰ê°€ ì´ë ¥ ë¡œë“œ"""
    try:
        # ë©”ì¸ ëŒ€ì‹œë³´ë“œì™€ ë™ì¼í•œ DB ê²½ë¡œ ì‚¬ìš©
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ data/db/evaluations.dbë¡œ ê²½ë¡œ ìˆ˜ì •
        project_root = Path(__file__).parent.parent.parent.parent.parent
        db_path = project_root / "data" / "db" / "evaluations.db"
        
        if not db_path.exists():
            return []
        
        conn = sqlite3.connect(str(db_path))
        
        query = '''
            SELECT timestamp, faithfulness, answer_relevancy, 
                   context_recall, context_precision, ragas_score
            FROM evaluations 
            ORDER BY timestamp DESC
            LIMIT 50
        '''
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if len(df) == 0:
            return []
        
        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        return df.to_dict('records')
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def show_evaluation_history_analysis(evaluation_history):
    """í‰ê°€ ì´ë ¥ ë¶„ì„ (ì‹¤ì œ ë°ì´í„°)"""
    st.subheader("ğŸ“ˆ í‰ê°€ ì‹¤í–‰ ì´ë ¥")
    
    if len(evaluation_history) < 2:
        st.info("ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•´ ë” ë§ì€ í‰ê°€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    df = pd.DataFrame(evaluation_history)
    
    # ê¸°ë³¸ í†µê³„
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ í‰ê°€ íšŸìˆ˜", len(evaluation_history))
    
    with col2:
        days_span = (df['timestamp'].max() - df['timestamp'].min()).days
        st.metric("í‰ê°€ ê¸°ê°„", f"{days_span}ì¼")
    
    with col3:
        avg_score = df['ragas_score'].mean()
        st.metric("í‰ê·  RAGAS ì ìˆ˜", f"{avg_score:.3f}")
    
    with col4:
        if days_span > 0:
            frequency = len(evaluation_history) / days_span
            st.metric("ì¼í‰ê·  í‰ê°€ íšŸìˆ˜", f"{frequency:.1f}íšŒ")
        else:
            st.metric("ì¼í‰ê·  í‰ê°€ íšŸìˆ˜", "ê³„ì‚°ë¶ˆê°€")
    
    # ì ìˆ˜ ì¶”ì´ ì°¨íŠ¸
    st.markdown("#### ğŸ“Š ì ìˆ˜ ì¶”ì´")
    
    fig = go.Figure()
    
    metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision', 'ragas_score']
    colors = ['blue', 'green', 'orange', 'red', 'purple']
    
    for metric, color in zip(metrics, colors):
        if metric in df.columns:
            fig.add_trace(go.Scatter(
                x=df['timestamp'],
                y=df[metric],
                mode='lines+markers',
                name=metric.replace('_', ' ').title(),
                line=dict(color=color)
            ))
    
    fig.update_layout(
        title="í‰ê°€ ì ìˆ˜ ì‹œê°„ë³„ ì¶”ì´",
        xaxis_title="ì‹œê°„",
        yaxis_title="ì ìˆ˜",
        yaxis=dict(range=[0, 1]),
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # ìµœì‹  ê²°ê³¼ ìš”ì•½
    if len(evaluation_history) > 0:
        latest = evaluation_history[0]
        st.markdown("#### ğŸ“‹ ìµœì‹  í‰ê°€ ê²°ê³¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**ì‹¤í–‰ ì‹œê°„**: {latest['timestamp']}")
            st.write(f"**RAGAS ì ìˆ˜**: {latest['ragas_score']:.3f}")
        
        with col2:
            st.write(f"**Faithfulness**: {latest['faithfulness']:.3f}")
            st.write(f"**Answer Relevancy**: {latest['answer_relevancy']:.3f}")

def show_api_usage_analysis(evaluation_history):
    """API ì‚¬ìš©ëŸ‰ ë¶„ì„ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)"""
    st.subheader("ğŸ”Œ API ì‚¬ìš© í˜„í™©")
    
    df = pd.DataFrame(evaluation_history)
    
    # ê¸°ë³¸ ì¶”ì •ì¹˜ (ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹Œ ê³„ì‚°ëœ ê°’)
    st.markdown("#### ğŸ“Š ì˜ˆìƒ API ì‚¬ìš©ëŸ‰")
    
    col1, col2 = st.columns(2)
    
    with col1:
        total_evaluations = len(evaluation_history)
        # RAGAS í‰ê°€ë‹¹ í‰ê·  API í˜¸ì¶œ ì¶”ì •
        estimated_llm_calls = total_evaluations * 8  # í‰ê°€ë‹¹ ì•½ 8íšŒ LLM í˜¸ì¶œ
        estimated_embedding_calls = total_evaluations * 4  # í‰ê°€ë‹¹ ì•½ 4íšŒ ì„ë² ë”© í˜¸ì¶œ
        
        st.metric("ì´ í‰ê°€ íšŸìˆ˜", total_evaluations)
        st.metric("ì˜ˆìƒ LLM API í˜¸ì¶œ", estimated_llm_calls)
        st.metric("ì˜ˆìƒ ì„ë² ë”© API í˜¸ì¶œ", estimated_embedding_calls)
    
    with col2:
        # í˜„ì¬ ì„¤ì •ëœ rate limit ì •ë³´
        st.markdown("**í˜„ì¬ API ì„¤ì •:**")
        st.write("- Gemini LLM: 1000 RPM (Tier 1)")
        st.write("- Gemini Embeddings: 10 RPM (Tier 1)")
        st.write("- Temperature: 0.0 (í‰ê°€ ì¼ê´€ì„±)")
        
        # ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„
        if total_evaluations > 0:
            # ì„ë² ë”©ì´ ë³‘ëª©ì´ë¯€ë¡œ ì„ë² ë”© ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
            estimated_time = (estimated_embedding_calls * 60) / 10  # 10 RPM
            st.metric("ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„", f"{estimated_time/60:.1f}ë¶„")
    
    # ì‚¬ìš©ëŸ‰ ì¶”ì´ (ì‹¤ì œ í‰ê°€ íšŸìˆ˜ ê¸°ë°˜)
    if len(df) > 1:
        st.markdown("#### ğŸ“ˆ í‰ê°€ ë¹ˆë„ ì¶”ì´")
        
        # ì¼ë³„ í‰ê°€ íšŸìˆ˜ ê³„ì‚°
        df['date'] = df['timestamp'].dt.date
        daily_counts = df.groupby('date').size().reset_index(name='count')
        daily_counts['date'] = pd.to_datetime(daily_counts['date'])
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=daily_counts['date'],
            y=daily_counts['count'],
            name='ì¼ë³„ í‰ê°€ íšŸìˆ˜',
            marker_color='lightblue'
        ))
        
        fig.update_layout(
            title="ì¼ë³„ í‰ê°€ ì‹¤í–‰ íšŸìˆ˜",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="í‰ê°€ íšŸìˆ˜",
            height=300
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # API ìµœì í™” íŒ
    st.markdown("#### ğŸ’¡ API ì‚¬ìš© ìµœì í™” íŒ")
    
    optimization_tips = [
        "ğŸ¯ **ë°°ì¹˜ í‰ê°€**: ì—¬ëŸ¬ QAë¥¼ í•œ ë²ˆì— í‰ê°€í•˜ì—¬ API í˜¸ì¶œ ìµœì í™”",
        "â° **Rate Limit ê´€ë¦¬**: í˜„ì¬ 10 RPM ì„ë² ë”© ì œí•œì´ ì£¼ìš” ë³‘ëª©",
        "ğŸ’° **ë¹„ìš© ì¶”ì •**: í‰ê°€ë‹¹ ì•½ $0.01-0.05 ì˜ˆìƒ (ëª¨ë¸ ë° ê¸¸ì´ì— ë”°ë¼ ë³€ë™)",
        "ğŸ”„ **ì¬í‰ê°€ ë°©ì§€**: ë™ì¼í•œ ë°ì´í„°ì…‹ ë°˜ë³µ í‰ê°€ ì£¼ì˜"
    ]
    
    for tip in optimization_tips:
        st.write(tip)

# ê¸°ì¡´ ëª¨ì˜ ë°ì´í„° í•¨ìˆ˜ë“¤ ì œê±°ë¨ - ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©