"""
RAGAS í‰ê°€ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ
ì§ê´€ì ì´ê³  ë¹„êµ ê°€ëŠ¥í•œ ì‹œê°í™” ì œê³µ
"""

import json
import sqlite3
from datetime import datetime
from pathlib import Path

import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from src.utils.paths import get_available_datasets, DATABASE_PATH, get_evaluation_data_path
# í˜ì´ì§€ ì •ì˜ (ê°„ë‹¨í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ëŒ€ì²´)
def load_pages():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í˜ì´ì§€ ëª©ë¡ ë°˜í™˜"""
    return {
        "ğŸ¯ Overview": "ë©”ì¸ ëŒ€ì‹œë³´ë“œ",
        "ğŸ“ˆ Historical": "ê³¼ê±° í‰ê°€ ê²°ê³¼",
        "ğŸ“š Detailed Analysis": "ìƒì„¸ ë¶„ì„",
        "ğŸ“– Metrics Explanation": "ë©”íŠ¸ë¦­ ì„¤ëª…",
        "âš¡ Performance": "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"
    }
from src.application.use_cases import RunEvaluationUseCase
from src.infrastructure.evaluation import RagasEvalAdapter
from src.infrastructure.llm.gemini_adapter import GeminiAdapter
from src.infrastructure.repository.file_adapter import FileRepositoryAdapter

# ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸
from src.presentation.web.components.detailed_analysis import show_detailed_analysis as show_detailed_component
from src.presentation.web.components.metrics_explanation import show_metrics_explanation as show_metrics_component
from src.presentation.web.components.performance_monitor import show_performance_monitor as show_performance_component

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="RAGTrace ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ì‚¬ì´ë“œë°” ---
st.sidebar.title("ğŸ” RAGTrace ëŒ€ì‹œë³´ë“œ")

# --- í˜ì´ì§€ ë¡œë“œ ë° ë¼ìš°íŒ… ---
pages = load_pages()
page_keys = list(pages.keys())

# í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ìƒíƒœ ê´€ë¦¬
if "selected_page" not in st.session_state:
    st.session_state.selected_page = "ğŸ¯ Overview"

# ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ìœ¼ë¡œ í˜ì´ì§€ ì´ë™ ì²˜ë¦¬
if "navigate_to" in st.session_state:
    st.session_state.selected_page = st.session_state.navigate_to
    del st.session_state.navigate_to


# í˜ì´ì§€ ì„ íƒ ì½œë°± í•¨ìˆ˜
def on_page_change():
    st.session_state.selected_page = st.session_state.page_selector


# ì‚¬ì´ë“œë°”ì—ì„œ í˜ì´ì§€ ì„ íƒ
st.sidebar.selectbox(
    "í˜ì´ì§€ ì„ íƒ",
    page_keys,
    index=page_keys.index(st.session_state.selected_page),
    key="page_selector",
    on_change=on_page_change,
)

page = st.session_state.selected_page

# --- ë©”ì¸ í˜ì´ì§€ ---
def main_page():
    st.title("ğŸ” RAGTrace - RAG ì„±ëŠ¥ ì¶”ì  ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")

    if ('evaluation_results' in st.session_state and
            st.session_state.evaluation_results):
        show_overview()
    else:
        show_overview()


def show_overview():
    """ë©”ì¸ ì˜¤ë²„ë·° ëŒ€ì‹œë³´ë“œ"""
    st.header("ğŸ“Š í‰ê°€ ê²°ê³¼ ê°œìš”")

    # ì•¡ì…˜ ë²„íŠ¼ë“¤
    col1, col2, col3, col4 = st.columns([2, 1, 1, 2])

    with col1:
        if st.button("ğŸš€ ìƒˆ í‰ê°€ ì‹¤í–‰", type="primary", help="ìƒˆë¡œìš´ RAG í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤"):
            run_new_evaluation()

    with col2:
        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", help="ìµœì‹  ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤"):
            st.rerun()

    with col3:
        if st.button("ğŸ“ˆ ì´ë ¥ë³´ê¸°", help="ê³¼ê±° í‰ê°€ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤"):
            st.session_state.navigate_to = "ğŸ“ˆ Historical"
            st.rerun()

    with col4:
        if st.button("ğŸ“š ë©”íŠ¸ë¦­ ê°€ì´ë“œ", help="RAGAS ì ìˆ˜ì˜ ì˜ë¯¸ë¥¼ ì•Œì•„ë³´ì„¸ìš”"):
            st.session_state.navigate_to = "ğŸ“– Metrics Explanation"
            st.rerun()

    # ìµœì‹  í‰ê°€ ê²°ê³¼ ë¡œë“œ
    latest_result = load_latest_result()

    if latest_result:
        show_metric_cards(latest_result)
        show_metric_charts(latest_result)
        show_recent_trends()
    else:
        st.info("ğŸ“ ì•„ì§ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 'ìƒˆ í‰ê°€ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì²« í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”!")
        st.markdown("---")
        st.markdown("### ğŸ¤” RAGAS ë©”íŠ¸ë¦­ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
        st.markdown("ğŸ“š ì‚¬ì´ë“œë°”ì—ì„œ **'Metrics Guide'**ë¥¼ ì„ íƒí•˜ë©´ ê° ì ìˆ˜ê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì‰½ê²Œ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")


def show_metric_cards(result):
    """ë©”íŠ¸ë¦­ ì¹´ë“œ í‘œì‹œ"""
    st.subheader("ğŸ¯ í•µì‹¬ ì§€í‘œ")

    col1, col2, col3, col4, col5 = st.columns(5)

    metrics = [
        ("ì¢…í•© ì ìˆ˜", result.get("ragas_score", 0), "ğŸ†"),
        ("Faithfulness", result.get("faithfulness", 0), "âœ…"),
        ("Answer Relevancy", result.get("answer_relevancy", 0), "ğŸ¯"),
        ("Context Recall", result.get("context_recall", 0), "ğŸ”„"),
        ("Context Precision", result.get("context_precision", 0), "ğŸ“"),
    ]

    for i, (name, value, icon) in enumerate(metrics):
        with [col1, col2, col3, col4, col5][i]:
            # ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ
            if value >= 0.8:
                color = "green"
            elif value >= 0.6:
                color = "orange"
            else:
                color = "red"

            # ì´ì „ í‰ê°€ì™€ì˜ ë¹„êµë¥¼ ìœ„í•œ ë¸íƒ€ ê³„ì‚°
            previous_result = get_previous_result()
            delta_value = None
            if previous_result and name.lower().replace(" ", "_") in previous_result:
                prev_value = previous_result[name.lower().replace(" ", "_")]
                delta_value = value - prev_value

            st.metric(
                label=f"{icon} {name}",
                value=f"{value:.3f}",
                delta=f"{delta_value:.3f}" if delta_value is not None else None,
            )


def show_metric_charts(result):
    """ë©”íŠ¸ë¦­ ì‹œê°í™” ì°¨íŠ¸"""
    st.subheader("ğŸ“ˆ ì‹œê°í™”")

    col1, col2 = st.columns(2)

    with col1:
        # ë ˆì´ë” ì°¨íŠ¸
        show_radar_chart(result)

    with col2:
        # ë°” ì°¨íŠ¸
        show_bar_chart(result)


def show_radar_chart(result):
    """ë ˆì´ë” ì°¨íŠ¸ ìƒì„±"""
    metrics = [
        "faithfulness",
        "answer_relevancy",
        "context_recall",
        "context_precision",
    ]
    values = [result.get(metric, 0) for metric in metrics]
    labels = ["Faithfulness", "Answer Relevancy", "Context Recall", "Context Precision"]

    fig = go.Figure()

    fig.add_trace(
        go.Scatterpolar(
            r=values + [values[0]],  # ì²« ë²ˆì§¸ ê°’ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€í•˜ì—¬ ì°¨íŠ¸ë¥¼ ë‹«ìŒ
            theta=labels + [labels[0]],
            fill="toself",
            name="RAGAS ì ìˆ˜",
            line_color="rgb(32, 201, 151)",
        )
    )

    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=True,
        title="ğŸ“Š ë©”íŠ¸ë¦­ ê· í˜•ë„",
        height=400,
    )

    st.plotly_chart(fig, use_container_width=True)


def show_bar_chart(result):
    """ë°” ì°¨íŠ¸ ìƒì„±"""
    metrics = [
        "faithfulness",
        "answer_relevancy",
        "context_recall",
        "context_precision",
    ]
    values = [result.get(metric, 0) for metric in metrics]
    labels = ["Faithfulness", "Answer Relevancy", "Context Recall", "Context Precision"]

    # ìƒ‰ìƒ ë§¤í•‘
    colors = ["green" if v >= 0.8 else "orange" if v >= 0.6 else "red" for v in values]

    fig = go.Figure(data=[go.Bar(x=labels, y=values, marker_color=colors)])

    fig.update_layout(
        title="ğŸ“Š ë©”íŠ¸ë¦­ë³„ ì„±ëŠ¥",
        yaxis_title="ì ìˆ˜",
        yaxis=dict(range=[0, 1]),
        height=400,
    )

    st.plotly_chart(fig, use_container_width=True)


def show_recent_trends():
    """ìµœê·¼ íŠ¸ë Œë“œ í‘œì‹œ"""
    st.subheader("ğŸ“ˆ ìµœê·¼ íŠ¸ë Œë“œ")

    # íˆìŠ¤í† ë¦¬ ë°ì´í„° ë¡œë“œ
    history = load_evaluation_history(limit=10)

    if len(history) > 1:
        df = pd.DataFrame(history)
        df["timestamp"] = pd.to_datetime(df["timestamp"])

        # íŠ¸ë Œë“œ ì°¨íŠ¸
        fig = go.Figure()

        metrics = [
            "faithfulness",
            "answer_relevancy",
            "context_recall",
            "context_precision",
            "ragas_score",
        ]
        colors = ["blue", "green", "orange", "red", "purple"]

        for metric, color in zip(metrics, colors):
            if metric in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df["timestamp"],
                        y=df[metric],
                        mode="lines+markers",
                        name=metric.replace("_", " ").title(),
                        line=dict(color=color),
                    )
                )

        fig.update_layout(
            title="ğŸ“ˆ í‰ê°€ ì ìˆ˜ íŠ¸ë Œë“œ",
            xaxis_title="ì‹œê°„",
            yaxis_title="ì ìˆ˜",
            yaxis=dict(range=[0, 1]),
            height=400,
        )

        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ğŸ“Š íŠ¸ë Œë“œ í‘œì‹œë¥¼ ìœ„í•´ ë” ë§ì€ í‰ê°€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")


def run_new_evaluation():
    """ìƒˆë¡œìš´ í‰ê°€ ì‹¤í–‰"""
    with st.spinner("ğŸ”„ í‰ê°€ë¥¼ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ ì˜µì…˜
            import os
            import random

            # ì¤‘ì•™ ê²½ë¡œ ê´€ë¦¬ ëª¨ë“ˆì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸°
            existing_datasets = get_available_datasets()

            if not existing_datasets:
                st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í‰ê°€ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ëœë¤í•˜ê²Œ ë°ì´í„°ì…‹ ì„ íƒ (ë‹¤ì–‘ì„±ì„ ìœ„í•´)
            selected_dataset = random.choice(existing_datasets)
            st.info(f"ğŸ“Š ì„ íƒëœ ë°ì´í„°ì…‹: {selected_dataset.split('/')[-1]}")

            # ê¸°ì¡´ í‰ê°€ ì„œë¹„ìŠ¤ í™œìš©
            llm_adapter = GeminiAdapter(model_name="gemini-2.5-flash-preview-05-20", requests_per_minute=1000)

            # ì¤‘ì•™ ê²½ë¡œ ê´€ë¦¬ ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ ê²½ë¡œ íšë“
            dataset_path = get_evaluation_data_path(selected_dataset)
            if not dataset_path:
                st.error(f"ë°ì´í„°ì…‹ '{selected_dataset}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            repository_adapter = FileRepositoryAdapter(file_path=str(dataset_path))

            ragas_eval_adapter = RagasEvalAdapter()

            evaluation_use_case = RunEvaluationUseCase(
                llm_port=llm_adapter,
                repository_port=repository_adapter,
                evaluation_runner=ragas_eval_adapter,
            )

            # í‰ê°€ ì‹¤í–‰
            evaluation_result = evaluation_use_case.execute()

            # ê²°ê³¼ ì €ì¥ (ë°ì´í„°ì…‹ ì •ë³´ í¬í•¨)
            result_dict = evaluation_result.to_dict()
            result_dict["metadata"]["dataset"] = selected_dataset

            # QA ë°ì´í„°ë„ í•¨ê»˜ ì €ì¥
            try:
                with open(dataset_path, "r", encoding="utf-8") as f:
                    qa_data = json.load(f)
                    # ì‹¤ì œ í‰ê°€ëœ ê°œìˆ˜ë§Œí¼ë§Œ ì €ì¥
                    qa_count = len(result_dict.get("individual_scores", []))
                    result_dict["qa_data"] = qa_data[:qa_count]
            except Exception as e:
                st.warning(f"QA ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

            save_evaluation_result(result_dict)

            st.success("âœ… í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()

        except Exception as e:
            st.error(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def show_historical():
    """íˆìŠ¤í† ë¦¬ í˜ì´ì§€"""
    st.header("ğŸ“ˆ í‰ê°€ ì´ë ¥")

    # ìƒì„¸ ë¶„ì„ìœ¼ë¡œ ì´ë™í•˜ëŠ” ì•ˆë‚´
    st.info("ğŸ’¡ íŠ¹ì • í‰ê°€ì˜ ìƒì„¸ ë¶„ì„ì„ ë³´ë ¤ë©´ 'ìƒì„¸ ë¶„ì„' í˜ì´ì§€ì—ì„œ í‰ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    history = load_evaluation_history()

    if history:
        df = pd.DataFrame(history)
        df["timestamp"] = pd.to_datetime(df["timestamp"])

        # í…Œì´ë¸” í‘œì‹œ ë° ìƒì„¸ ë¶„ì„ ë²„íŠ¼ ì¶”ê°€
        st.subheader("ğŸ“‹ í‰ê°€ ì´ë ¥ í…Œì´ë¸”")

        # ê° í‰ê°€ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ì™€ ìƒì„¸ ë¶„ì„ ë²„íŠ¼
        for i, row in df.iterrows():
            with st.expander(f"í‰ê°€ #{i+1} - {row['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}"):
                col1, col2, col3 = st.columns([2, 2, 1])

                with col1:
                    st.metric("RAGAS ì ìˆ˜", f"{row.get('ragas_score', 0):.3f}")
                    st.metric("Faithfulness", f"{row.get('faithfulness', 0):.3f}")

                with col2:
                    st.metric("Answer Relevancy", f"{row.get('answer_relevancy', 0):.3f}")
                    st.metric("Context Recall", f"{row.get('context_recall', 0):.3f}")

                with col3:
                    st.metric("Context Precision", f"{row.get('context_precision', 0):.3f}")

                    # ìƒì„¸ ë¶„ì„ í˜ì´ì§€ë¡œ ì´ë™ ë²„íŠ¼
                    if st.button(f"ğŸ” ìƒì„¸ ë¶„ì„", key=f"detail_btn_{i}"):
                        # ì„ íƒëœ í‰ê°€ ì¸ë±ìŠ¤ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                        st.session_state.selected_evaluation_index = i
                        st.session_state.navigate_to = "ğŸ“š Detailed Analysis"
                        st.rerun()

        # ì „ì²´ í…Œì´ë¸”ë„ í‘œì‹œ
        st.subheader("ğŸ“Š ì „ì²´ í‰ê°€ ì´ë ¥")
        st.dataframe(df, use_container_width=True)

        # ìƒì„¸ ë¹„êµ ì°¨íŠ¸
        st.subheader("ğŸ“Š í‰ê°€ ë¹„êµ")

        if len(df) > 1:
            # ì‚¬ìš©ìê°€ ë¹„êµí•  í‰ê°€ ì„ íƒ
            col1, col2 = st.columns(2)

            with col1:
                eval1_idx = st.selectbox(
                    "ì²« ë²ˆì§¸ í‰ê°€",
                    range(len(df)),
                    format_func=lambda x: f"{df.iloc[x]['timestamp'].strftime('%Y-%m-%d %H:%M')} (#{x+1})",
                )

            with col2:
                eval2_idx = st.selectbox(
                    "ë‘ ë²ˆì§¸ í‰ê°€",
                    range(len(df)),
                    index=min(1, len(df) - 1),
                    format_func=lambda x: f"{df.iloc[x]['timestamp'].strftime('%Y-%m-%d %H:%M')} (#{x+1})",
                )

            if eval1_idx != eval2_idx:
                show_comparison_chart(df.iloc[eval1_idx], df.iloc[eval2_idx])

    else:
        st.info("ğŸ“ ì•„ì§ í‰ê°€ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")


def show_comparison_chart(eval1, eval2):
    """ë‘ í‰ê°€ ê²°ê³¼ ë¹„êµ ì°¨íŠ¸"""
    metrics = [
        "faithfulness",
        "answer_relevancy",
        "context_recall",
        "context_precision",
        "ragas_score",
    ]

    fig = go.Figure()

    fig.add_trace(
        go.Bar(
            name=f'í‰ê°€ 1 ({eval1["timestamp"]})',
            x=metrics,
            y=[eval1.get(m, 0) for m in metrics],
            marker_color="lightblue",
        )
    )

    fig.add_trace(
        go.Bar(
            name=f'í‰ê°€ 2 ({eval2["timestamp"]})',
            x=metrics,
            y=[eval2.get(m, 0) for m in metrics],
            marker_color="darkblue",
        )
    )

    fig.update_layout(title="ğŸ“Š í‰ê°€ ê²°ê³¼ ë¹„êµ", barmode="group", yaxis=dict(range=[0, 1]), height=400)

    st.plotly_chart(fig, use_container_width=True)


def show_detailed_analysis():
    """ìƒì„¸ ë¶„ì„ í˜ì´ì§€"""
    show_detailed_component()


def show_metrics_guide():
    """ë©”íŠ¸ë¦­ ê°€ì´ë“œ í˜ì´ì§€"""
    show_metrics_component()


def show_performance():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í˜ì´ì§€"""
    show_performance_component()


# ë°ì´í„° ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤


def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    db_path = DATABASE_PATH
    db_path.parent.mkdir(exist_ok=True)

    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()

    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS evaluations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT NOT NULL,
            faithfulness REAL,
            answer_relevancy REAL,
            context_recall REAL,
            context_precision REAL,
            ragas_score REAL,
            raw_data TEXT
        )
    """
    )

    conn.commit()
    conn.close()


def save_evaluation_result(result):
    """í‰ê°€ ê²°ê³¼ ì €ì¥"""
    init_db()

    conn = sqlite3.connect(str(DATABASE_PATH))
    cursor = conn.cursor()

    cursor.execute(
        """
        INSERT INTO evaluations (
            timestamp, faithfulness, answer_relevancy, 
            context_recall, context_precision, ragas_score, raw_data
        ) VALUES (?, ?, ?, ?, ?, ?, ?)
    """,
        (
            datetime.now().isoformat(),
            result.get("faithfulness", 0),
            result.get("answer_relevancy", 0),
            result.get("context_recall", 0),
            result.get("context_precision", 0),
            result.get("ragas_score", 0),
            json.dumps(result),
        ),
    )

    conn.commit()
    conn.close()


def load_latest_result():
    """ìµœì‹  í‰ê°€ ê²°ê³¼ ë¡œë“œ"""
    history = load_evaluation_history(limit=1)
    return history[0] if history else None


def load_evaluation_history(limit=None):
    """í‰ê°€ ì´ë ¥ ë¡œë“œ"""
    init_db()

    conn = sqlite3.connect(str(DATABASE_PATH))

    query = """
        SELECT timestamp, faithfulness, answer_relevancy, 
               context_recall, context_precision, ragas_score
        FROM evaluations 
        ORDER BY timestamp DESC
    """

    if limit:
        query += f" LIMIT {limit}"

    df = pd.read_sql_query(query, conn)
    conn.close()

    return df.to_dict("records")


def get_previous_result():
    """ì´ì „ í‰ê°€ ê²°ê³¼ ë°˜í™˜"""
    history = load_evaluation_history(limit=2)
    return history[1] if len(history) > 1 else None


# --- í˜ì´ì§€ ë¼ìš°íŒ… ---
if page == "ğŸ¯ Overview":
    main_page()
elif page == "ğŸ“ˆ Historical":
    show_historical()
elif page == "ğŸ“š Detailed Analysis":
    show_detailed_analysis()
elif page == "ğŸ“– Metrics Explanation":
    show_metrics_guide()
elif page == "âš¡ Performance":
    show_performance()
else:
    main_page()
