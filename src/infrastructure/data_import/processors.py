"""
Batch Data Processors

ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ.
ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì¥ì•  ë³µêµ¬ ëŠ¥ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from typing import List, Iterator, Callable, Optional, Dict, Any
from dataclasses import dataclass, field
import asyncio
import time
from pathlib import Path
import json
import uuid
from datetime import datetime

from ...domain.entities.evaluation_data import EvaluationData
from ...domain.entities.evaluation_result import EvaluationResult


@dataclass
class BatchProgress:
    """ë°°ì¹˜ ì²˜ë¦¬ ì§„í–‰ ìƒí™©"""
    batch_id: str
    current_batch: int
    total_batches: int
    processed_items: int
    total_items: int
    start_time: datetime
    current_time: datetime = field(default_factory=datetime.now)
    errors: List[str] = field(default_factory=list)
    
    @property
    def progress_percentage(self) -> float:
        """ì§„í–‰ë¥  (0.0 ~ 1.0)"""
        if self.total_items == 0:
            return 0.0
        return self.processed_items / self.total_items
    
    @property
    def elapsed_time(self) -> float:
        """ê²½ê³¼ ì‹œê°„ (ì´ˆ)"""
        return (self.current_time - self.start_time).total_seconds()
    
    @property
    def items_per_second(self) -> float:
        """ì´ˆë‹¹ ì²˜ë¦¬ í•­ëª© ìˆ˜"""
        if self.elapsed_time == 0:
            return 0.0
        return self.processed_items / self.elapsed_time
    
    @property
    def estimated_remaining_time(self) -> float:
        """ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ (ì´ˆ)"""
        if self.items_per_second == 0:
            return 0.0
        remaining_items = self.total_items - self.processed_items
        return remaining_items / self.items_per_second


@dataclass 
class BatchConfig:
    """ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •"""
    batch_size: int = 50
    max_retries: int = 3
    retry_delay: float = 1.0
    save_intermediate_results: bool = True
    intermediate_save_path: Optional[Path] = None
    enable_progress_callback: bool = True
    max_concurrent_batches: int = 1  # ë™ì‹œ ì²˜ë¦¬í•  ë°°ì¹˜ ìˆ˜


class BatchDataProcessor:
    """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ê¸°"""
    
    def __init__(self, config: Optional[BatchConfig] = None):
        self.config = config or BatchConfig()
        self.current_progress: Optional[BatchProgress] = None
        self.progress_callbacks: List[Callable[[BatchProgress], None]] = []
    
    def add_progress_callback(self, callback: Callable[[BatchProgress], None]):
        """ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜ ì¶”ê°€"""
        self.progress_callbacks.append(callback)
    
    def create_batches(self, data_list: List[EvaluationData]) -> Iterator[List[EvaluationData]]:
        """ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„í• """
        batch_size = self.config.batch_size
        for i in range(0, len(data_list), batch_size):
            yield data_list[i:i + batch_size]
    
    async def process_batches_async(self,
                                   data_list: List[EvaluationData],
                                   processor_func: Callable[[List[EvaluationData]], List[EvaluationResult]]) -> List[EvaluationResult]:
        """ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬"""
        batch_id = str(uuid.uuid4())[:8]
        batches = list(self.create_batches(data_list))
        
        # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
        self.current_progress = BatchProgress(
            batch_id=batch_id,
            current_batch=0,
            total_batches=len(batches),
            processed_items=0,
            total_items=len(data_list),
            start_time=datetime.now()
        )
        
        all_results = []
        
        # ë°°ì¹˜ ì²˜ë¦¬ (í˜„ì¬ëŠ” ìˆœì°¨ ì²˜ë¦¬, ì¶”í›„ ë³‘ë ¬ ì²˜ë¦¬ í™•ì¥ ê°€ëŠ¥)
        for batch_idx, batch_data in enumerate(batches):
            try:
                # ë°°ì¹˜ ì²˜ë¦¬ ì‹œë„
                batch_results = await self._process_single_batch_with_retry(
                    batch_data, processor_func, batch_idx + 1
                )
                
                all_results.extend(batch_results)
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                self.current_progress.current_batch = batch_idx + 1
                self.current_progress.processed_items += len(batch_data)
                self.current_progress.current_time = datetime.now()
                
                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                if self.config.save_intermediate_results:
                    await self._save_intermediate_results(all_results, batch_idx + 1)
                
                # ì§„í–‰ ìƒí™© ì½œë°± í˜¸ì¶œ
                if self.config.enable_progress_callback:
                    for callback in self.progress_callbacks:
                        callback(self.current_progress)
                
            except Exception as e:
                error_msg = f"ë°°ì¹˜ {batch_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                self.current_progress.errors.append(error_msg)
                print(f"âŒ {error_msg}")
                # ì˜¤ë¥˜ ë°œìƒí•´ë„ ë‹¤ìŒ ë°°ì¹˜ ê³„ì† ì²˜ë¦¬
                continue
        
        return all_results
    
    def process_batches_sync(self,
                            data_list: List[EvaluationData],
                            processor_func: Callable[[List[EvaluationData]], List[EvaluationResult]]) -> List[EvaluationResult]:
        """ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í˜¸í™˜)"""
        return asyncio.run(self.process_batches_async(data_list, processor_func))
    
    async def _process_single_batch_with_retry(self,
                                              batch_data: List[EvaluationData],
                                              processor_func: Callable[[List[EvaluationData]], List[EvaluationResult]],
                                              batch_number: int) -> List[EvaluationResult]:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë‹¨ì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        last_exception = None
        
        for attempt in range(self.config.max_retries):
            try:
                print(f"ğŸ”„ ë°°ì¹˜ {batch_number} ì²˜ë¦¬ ì¤‘... (ì‹œë„ {attempt + 1}/{self.config.max_retries})")
                
                # ì‹¤ì œ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
                if asyncio.iscoroutinefunction(processor_func):
                    results = await processor_func(batch_data)
                else:
                    results = processor_func(batch_data)
                
                print(f"âœ… ë°°ì¹˜ {batch_number} ì™„ë£Œ ({len(results)}ê°œ ê²°ê³¼)")
                return results
                
            except Exception as e:
                last_exception = e
                print(f"âš ï¸ ë°°ì¹˜ {batch_number} ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
                
                if attempt < self.config.max_retries - 1:
                    await asyncio.sleep(self.config.retry_delay)
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        raise Exception(f"ë°°ì¹˜ {batch_number} ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {str(last_exception)}")
    
    async def _save_intermediate_results(self, results: List[EvaluationResult], batch_number: int):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        if not self.config.intermediate_save_path:
            return
        
        try:
            save_path = self.config.intermediate_save_path
            save_path.mkdir(parents=True, exist_ok=True)
            
            # ë°°ì¹˜ë³„ ê²°ê³¼ ì €ì¥
            batch_file = save_path / f"batch_{batch_number:04d}_results.json"
            
            # EvaluationResultë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_results = []
            for result in results:
                serializable_results.append({
                    'evaluation_id': result.evaluation_id,
                    'dataset_name': result.dataset_name,
                    'model_name': result.model_name,
                    'embedding_model_name': getattr(result, 'embedding_model_name', 'unknown'),
                    'prompt_type': getattr(result, 'prompt_type', 'default'),
                    'metrics': result.metrics.to_dict() if hasattr(result.metrics, 'to_dict') else {},
                    'individual_scores': result.individual_scores,
                    'evaluation_time': result.evaluation_time.isoformat() if result.evaluation_time else None,
                    'data_count': result.data_count
                })
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"âš ï¸ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def get_progress_summary(self) -> Optional[str]:
        """í˜„ì¬ ì§„í–‰ ìƒí™© ìš”ì•½ ë°˜í™˜"""
        if not self.current_progress:
            return None
        
        progress = self.current_progress
        
        summary_lines = [
            f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì§„í–‰ ìƒí™© (ID: {progress.batch_id})",
            f"   ì§„í–‰ë¥ : {progress.progress_percentage:.1%} ({progress.processed_items}/{progress.total_items})",
            f"   ë°°ì¹˜: {progress.current_batch}/{progress.total_batches}",
            f"   ê²½ê³¼ ì‹œê°„: {progress.elapsed_time:.1f}ì´ˆ",
            f"   ì²˜ë¦¬ ì†ë„: {progress.items_per_second:.1f} í•­ëª©/ì´ˆ",
        ]
        
        if progress.estimated_remaining_time > 0:
            summary_lines.append(f"   ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {progress.estimated_remaining_time:.1f}ì´ˆ")
        
        if progress.errors:
            summary_lines.append(f"   âŒ ì˜¤ë¥˜: {len(progress.errors)}ê°œ")
        
        return "\n".join(summary_lines)


class ProgressDisplayCallback:
    """ì½˜ì†”ìš© ì§„í–‰ ìƒí™© í‘œì‹œ ì½œë°±"""
    
    def __init__(self, update_interval: float = 2.0):
        self.update_interval = update_interval
        self.last_update_time = 0.0
    
    def __call__(self, progress: BatchProgress):
        """ì§„í–‰ ìƒí™© ì½˜ì†” ì¶œë ¥"""
        current_time = time.time()
        
        # ì—…ë°ì´íŠ¸ ê°„ê²© ì²´í¬
        if current_time - self.last_update_time < self.update_interval:
            return
        
        self.last_update_time = current_time
        
        # ì§„í–‰ë¥  ë°” ìƒì„±
        bar_length = 30
        filled_length = int(bar_length * progress.progress_percentage)
        bar = 'â–ˆ' * filled_length + 'â–’' * (bar_length - filled_length)
        
        print(f"\rğŸ”„ [{bar}] {progress.progress_percentage:.1%} "
              f"({progress.processed_items}/{progress.total_items}) "
              f"- {progress.items_per_second:.1f} í•­ëª©/ì´ˆ "
              f"- ë‚¨ì€ ì‹œê°„: {progress.estimated_remaining_time:.0f}ì´ˆ", end='', flush=True)
        
        # ë°°ì¹˜ ì™„ë£Œ ì‹œ ìƒˆ ì¤„
        if progress.current_batch == progress.total_batches:
            print()  # ìƒˆ ì¤„